A beginner-friendly machine learning project implementing Linear Regression from scratch with Gradient Descent for parameter optimization.

ğŸ“Œ Overview

This project demonstrates how linear regression works internally without using high-level machine learning libraries.
It explains:

How to model a linear relationship between input X and output Y

How to compute predictions

How to calculate cost (Mean Squared Error)

How to update parameters using gradient descent

How to track loss reduction over training

This is a great reference for understanding the fundamentals of machine learning.

ğŸ¯ Features
âœ”ï¸ Gradient Descent Optimizer

Manual implementation of parameter updates:

ğœƒ
=
ğœƒ
âˆ’
ğ›¼
â‹…
âˆ‚
ğ½
âˆ‚
ğœƒ
Î¸=Î¸âˆ’Î±â‹…
âˆ‚Î¸
âˆ‚J
	â€‹

âœ”ï¸ Cost Function (MSE)

Measures accuracy of the linear model:

ğ½
=
1
2
ğ‘š
âˆ‘
(
â„
(
ğ‘¥
)
âˆ’
ğ‘¦
)
2
J=
2m
1
	â€‹

âˆ‘(h(x)âˆ’y)
2
âœ”ï¸ Visualization

Loss vs. Iterations

Best-fit regression line

âœ”ï¸ Easy to Modify

Change:

Learning rate

Number of iterations

Dataset

ğŸ§  Mathematical Background
Hypothesis function
â„
ğœƒ
(
ğ‘¥
)
=
ğœƒ
0
+
ğœƒ
1
ğ‘¥
h
Î¸
	â€‹

(x)=Î¸
0
	â€‹

+Î¸
1
	â€‹

x
Cost function
ğ½
(
ğœƒ
0
,
ğœƒ
1
)
=
1
2
ğ‘š
âˆ‘
ğ‘–
=
1
ğ‘š
(
â„
ğœƒ
(
ğ‘¥
ğ‘–
)
âˆ’
ğ‘¦
ğ‘–
)
2
J(Î¸
0
	â€‹

,Î¸
1
	â€‹

)=
2m
1
	â€‹

i=1
âˆ‘
m
	â€‹

(h
Î¸
	â€‹

(x
i
	â€‹

)âˆ’y
i
	â€‹

)
2
Gradient Descent updates
ğœƒ
0
:
=
ğœƒ
0
âˆ’
ğ›¼
â‹…
1
ğ‘š
âˆ‘
(
â„
ğœƒ
(
ğ‘¥
ğ‘–
)
âˆ’
ğ‘¦
ğ‘–
)
Î¸
0
	â€‹

:=Î¸
0
	â€‹

âˆ’Î±â‹…
m
1
	â€‹

âˆ‘(h
Î¸
	â€‹

(x
i
	â€‹

)âˆ’y
i
	â€‹

)
ğœƒ
1
:
=
ğœƒ
1
âˆ’
ğ›¼
â‹…
1
ğ‘š
âˆ‘
[
(
â„
ğœƒ
(
ğ‘¥
ğ‘–
)
âˆ’
ğ‘¦
ğ‘–
)
ğ‘¥
ğ‘–
]
Î¸
1
	â€‹

:=Î¸
1
	â€‹

âˆ’Î±â‹…
m
1
	â€‹

âˆ‘[(h
Î¸
	â€‹

(x
i
	â€‹

)âˆ’y
i
	â€‹

)x
i
	â€‹

]
ğŸ“ Project Structure
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.csv
â”œâ”€â”€ linear_regression.py
â”œâ”€â”€ gradient_descent.py
â”œâ”€â”€ visualize.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
